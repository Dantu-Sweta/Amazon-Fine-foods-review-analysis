{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a2a052-6c6d-4e0a-b4d5-c36e01122a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd85cd04-3925-4fca-91af-0c670bf4fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the file path in a variable\n",
    "file_path = \"foods.txt\"\n",
    "\n",
    "# Reading the content of the files using readlines\n",
    "# readlines reads each line in a iteration\n",
    "# Storing all the data in the variable file_data\n",
    "with open(file_path, 'r') as file:\n",
    "    file_data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33318b2-9b36-4d12-91a5-d94092aa563e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sameple data of productIds:  ['B001E4KFG0', 'B00813GRG4', 'B000LQOCH0', 'B000UA0QIQ', 'B006K2ZZ7K']\n",
      "Sameple data of userIds:  ['A3SGXH7AUHU8GW', 'A1D87F6ZCVE5NK', 'ABXLMWJIXXAIN', 'A395BORC6FGVXV', 'A1UQRSCLF8GW1T']\n",
      "Sameple data of profileNames:  ['delmartian', 'dll pa', 'Natalia Corres \"Natalia Corres\"', 'Karl', 'Michael D. Bigham \"M. Wassir\"']\n",
      "Sameple data of helpfulness:  ['1/1', '0/0', '1/1', '3/3', '0/0']\n",
      "Sameple data of scores:  ['5.0', '1.0', '4.0', '2.0', '5.0']\n",
      "Sameple data of times:  ['1303862400', '1346976000', '1219017600', '1307923200', '1350777600']\n",
      "Sameple data of summaries:  ['Good Quality Dog Food', 'Not as Advertised', '\"Delight\" says it all', 'Cough Medicine', 'Great taffy']\n",
      "Sameple data of texts:  ['I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.', 'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".']\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty lists of each column of the our dataframe\n",
    "productIds, userIds, profileNames, helpfulness, scores, times, summaries, texts = ([] for _ in range(8))\n",
    "\n",
    "# Going through each line of the data and appending them into different columns (separating the data column wise)\n",
    "for line in file_data:\n",
    "    if line.startswith('product/productId:'):\n",
    "        productIds.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/userId:'):\n",
    "        userIds.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/profileName:'):\n",
    "        profileNames.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/helpfulness:'):\n",
    "        helpfulness.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/score:'):\n",
    "        scores.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/time:'):\n",
    "        times.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/summary:'):\n",
    "        summaries.append(line.split(': ')[1].strip())\n",
    "    elif line.startswith('review/text:'):\n",
    "        texts.append(line.split(': ')[1].strip())\n",
    "\n",
    "# checking if the data split correctly into different columns\n",
    "print(\"Sameple data of productIds: \", productIds[:5])\n",
    "print(\"Sameple data of userIds: \", userIds[:5])\n",
    "print(\"Sameple data of profileNames: \", profileNames[:5])\n",
    "print(\"Sameple data of helpfulness: \", helpfulness[:5])\n",
    "print(\"Sameple data of scores: \", scores[:5])\n",
    "print(\"Sameple data of times: \", times[:5])\n",
    "print(\"Sameple data of summaries: \", summaries[:5])\n",
    "print(\"Sameple data of texts: \", texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0837d428-7422-4836-9124-26bc287cf9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product/productId</th>\n",
       "      <th>review/userId</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0/0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3/3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0/0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2/2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product/productId   review/userId               review/profileName  \\\n",
       "0             B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1             B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2             B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3             B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4             B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...                  ...             ...                              ...   \n",
       "568449        B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450        B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451        B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452        B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453        B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "       review/helpfulness review/score review/time  \\\n",
       "0                     1/1          5.0  1303862400   \n",
       "1                     0/0          1.0  1346976000   \n",
       "2                     1/1          4.0  1219017600   \n",
       "3                     3/3          2.0  1307923200   \n",
       "4                     0/0          5.0  1350777600   \n",
       "...                   ...          ...         ...   \n",
       "568449                0/0          5.0  1299628800   \n",
       "568450                0/0          2.0  1331251200   \n",
       "568451                2/2          5.0  1329782400   \n",
       "568452                1/1          5.0  1331596800   \n",
       "568453                0/0          5.0  1338422400   \n",
       "\n",
       "                            review/summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                              review/text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a data frame with the above column data \n",
    "foods_df = pd.DataFrame({\n",
    "    'product/productId': productIds,\n",
    "    'review/userId': userIds,\n",
    "    'review/profileName': profileNames,\n",
    "    'review/helpfulness': helpfulness,\n",
    "    'review/score': scores,\n",
    "    'review/time': times,\n",
    "    'review/summary': summaries,\n",
    "    'review/text': texts\n",
    "})\n",
    "foods_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b6b836-4057-4e3e-b686-eb0aeee1060b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product/productId     0\n",
       "review/userId         0\n",
       "review/profileName    0\n",
       "review/helpfulness    0\n",
       "review/score          0\n",
       "review/time           0\n",
       "review/summary        0\n",
       "review/text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data\n",
    "foods_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89587fc8-0eb9-464c-940e-0d1bcedfe89d",
   "metadata": {},
   "source": [
    "ML text classifications makes a classification based on the prior observation/previous observations\n",
    "Steps to do(train) text-classifcation are as follows\n",
    "\n",
    "1. Feature extraction: Converting pieces of text into mathematical structure (vector). This involves creating new features that still contain the necessary/important information from the original data but in a more efficient way.\n",
    "Ways to perform feature extraction\n",
    "a. PCA (principal component analysis): statistical method to transform data into a new coordinate system\n",
    "b. LDA (linear discriminant analysis): find linear combinations of features that best separate two or more features.\n",
    "...\n",
    "Most common method (for text) is bag of words: It is  a short way of extracting features from text. It represents the text that describes occurance of words within a document.The model is only concerned about if a certain word is present in a document or not.\n",
    "\n",
    "Popular ML algorithms for text classification are:\n",
    "1. Naive Bayes\n",
    "2. SVM\n",
    "3. DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76172d8-6d71-4c86-b005-849e42592973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Naive Bayes to construct a classifier\n",
    "# Collecting all the features \n",
    "features = ['review/userId', 'review/profileName', 'review/time', 'review/summary', 'review/text']\n",
    "X = foods_df[features]\n",
    "y = foods_df['review/score']\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Text parts of the X data\n",
    "# X_text = foods_df['review/summary'] + ' ' + foods_df['review/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ec65efd-4a1a-4a46-ba00-85e589bff07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the data\n",
    "# Instantiate CountVectorizer (vectorizer)\n",
    "# Bags of words\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the data\n",
    "# learning the 'vocabulary'of the data\n",
    "a = vectorizer.fit(X_train['review/summary'] + ' ' + X_train['review/text'])\n",
    "vectorizer.fit(X_test['review/summary'] + ' ' + X_test['review/text'])\n",
    "\n",
    "# check the fitted data (vocabulary)\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "# Tranforming the data into a mathematical matrix that tells us the frequency of terms (document-term matrix)\n",
    "X_train_text = vectorizer.transform(X_train)\n",
    "X_test_text = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4969f6f7-bc1f-4529-b40d-85f5db0d0158",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Or do both at once\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Instantiate CountVectorizer (vectorizer)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[1;32m----> 5\u001b[0m X_train_text \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview/summary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview/text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# we use the same vectorizer to transform test data. This ensures that the test data is represented in the same numerical format as training data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# vectorizer uses the vocabularly learnt during the  training \u001b[39;00m\n\u001b[0;32m      8\u001b[0m X_test_text \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview/summary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview/text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Or do both at once\n",
    "# Instantiate CountVectorizer (vectorizer)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_text = vectorizer.fit_transform(X_train['review/summary'] + ' ' + X_train['review/text'])\n",
    "# we use the same vectorizer to transform test data. This ensures that the test data is represented in the same numerical format as training data\n",
    "# vectorizer uses the vocabularly learnt during the  training \n",
    "X_test_text = vectorizer.transform(X_test['review/summary'] + ' ' + X_test['review/text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a647a16-6c66-4233-9912-f2fea13ee88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c52038-442b-4f49-bd02-e05083cbbcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(force_alpha=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(force_alpha=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(force_alpha=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a naive bayes classifier\n",
    "classifier = MultinomialNB(force_alpha=True)\n",
    "\n",
    "# fit the data to the classifier\n",
    "classifier.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dedc6f07-73e4-415a-a5f1-d039e7f680ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7174195273496184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_prediction = classifier.predict(X_test_text)\n",
    "\n",
    "# check the accuracy\n",
    "accuracy = accuracy_score(y_test, y_prediction)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3679d-2309-46b7-90e4-23d86a176227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f39bc1-f5a1-40a6-bcc3-d5b7169c5f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
